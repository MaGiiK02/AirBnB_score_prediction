{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move workidir to the correct folder\n",
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Custom Libs\n",
    "from dataset.dataset import Dataset\n",
    "from model.models.listings_regressor import MLPRegressor, LossAccCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up which conlumn to use as a target :\n",
    "# 'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', \n",
    "# 'review_scores_communication', 'review_scores_location', 'review_scores_value',\n",
    "\n",
    "# Note: not defined for scores\n",
    "\n",
    "# REFERENCE_COlUMN = \"review_scores_rating\"\n",
    "# buckets = [(0, 3), (3, 4), (4, 4.5), (4.5, 5)]\n",
    "# OUTLIERS_LOW = -np.inf\n",
    "# OUTLIERS_HIGH = +np.inf\n",
    "\n",
    "REFERENCE_COlUMN = \"price\"\n",
    "BUCKETS = [(50, 100), (100, 200), (300, 400), (400, 500)]\n",
    "OUTLIERS_LOW = 50\n",
    "OUTLIERS_HIGH = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiments Reproducibility\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "seed_everything(42, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the precleaned and spearated datset\n",
    "with open(f'./dataset/train_dataset.pkl', 'rb') as f:\n",
    "    train_dataset = pd.read_pickle(f)\n",
    "\n",
    "with open(f'./dataset/test_dataset.pkl', 'rb') as f:\n",
    "    test_dataset = pd.read_pickle(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not_embeddings_shape (5598, 146)\n"
     ]
    }
   ],
   "source": [
    "y_train = train_dataset.getAllScores()[REFERENCE_COlUMN]\n",
    "x_not_embeddings_train = train_dataset.getListingsNotEmbeddings()\n",
    "print(\"not_embeddings_shape\", x_not_embeddings_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA to non embeddings fields + normalization\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Note that the PCA and the scaler are kept to be reused in the test\n",
    "pca = PCA(n_components=60)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "x_not_embeddings_train = x_not_embeddings_train.fillna(0)\n",
    "x_not_embeddings_train_scaled = scaler.fit_transform(x_not_embeddings_train)\n",
    "x_not_embeddings_train_60 = pca.fit_transform(x_not_embeddings_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  define X and y for training\n",
    "X_train = x_not_embeddings_train_60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not_embeddings_shape (1400, 146)\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare Test\n",
    "y_test = test_dataset.getAllScores()[REFERENCE_COlUMN]\n",
    "x_not_embeddings_test = test_dataset.getListingsNotEmbeddings()\n",
    "print(\"not_embeddings_shape\", x_not_embeddings_test.shape)\n",
    "\n",
    "# PCA for dimensionality reduction\n",
    "pca = PCA(n_components=60)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "x_not_embeddings_test = x_not_embeddings_test.fillna(0)\n",
    "x_not_embeddings_test_scaled = scaler.fit_transform(x_not_embeddings_test)\n",
    "x_not_embeddings_test_60 = pca.fit_transform(x_not_embeddings_test_scaled)\n",
    "\n",
    "X_test = x_not_embeddings_test_60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "# Drop nan values based on target conlumn\n",
    "empty_target_indexes_train = y_train.notna()\n",
    "X_train = X_train[empty_target_indexes_train]\n",
    "y_train = y_train[empty_target_indexes_train]\n",
    "\n",
    "empty_target_indexes_test = y_test.notna()\n",
    "X_test = X_test[empty_target_indexes_test]\n",
    "y_test = y_test[empty_target_indexes_test]\n",
    "\n",
    "## Appling cutout\n",
    "not_outliers_idx = y_train <= OUTLIERS_HIGH\n",
    "not_outliers_idx_2 = y_train[y_train <= OUTLIERS_HIGH] >= OUTLIERS_LOW\n",
    "X_train = X_train[not_outliers_idx][not_outliers_idx_2]\n",
    "y_train = y_train[not_outliers_idx][not_outliers_idx_2]\n",
    "\n",
    "not_outliers_idx = y_test <= OUTLIERS_HIGH\n",
    "not_outliers_idx_2 = y_test[y_test <= OUTLIERS_HIGH] >= OUTLIERS_LOW\n",
    "X_test = X_test[not_outliers_idx][not_outliers_idx_2]\n",
    "y_test = y_test[not_outliers_idx][not_outliers_idx_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucket generations\n",
    "def bucketizie(x):\n",
    "    for i in range(len(buckets)):\n",
    "        start, end = buckets[i]\n",
    "        if (i == 0): \n",
    "            if x >= start and  x<=end: return i\n",
    "        else:\n",
    "            if x > start and  x<=end: return i\\\n",
    "    return len(BUCKETS)\n",
    "\n",
    "y_train_buckets = [bucketizie(val) for val in y_train]\n",
    "y_test_buckets = [bucketizie(val) for val in y_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An util function to plot the result of a trained model on the test data\n",
    "from sklearn import metrics\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def evaluate_and_display(model, x, y):\n",
    "    y_hat = None\n",
    "    if  type(XGBClassifier()) == type(model):\n",
    "        y_hat = model.predict(x).round()\n",
    "    else:\n",
    "        y_hat = model.transform(x).round()\n",
    "\n",
    "    # print reference\n",
    "    for i in range(len(BUCKETS)):\n",
    "        start, end = BUCKETS[i]\n",
    "        print(f\"Bucket {i}-> {start}-{end}\")\n",
    " \n",
    "    ## Confusion\n",
    "    cm = metrics.confusion_matrix(y, y_hat)\n",
    "    disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "\n",
    "    ## ROC\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y, y_hat, pos_label=2)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "    print(\"AUC:\", auc)\n",
    "\n",
    "    # Accuracy\n",
    "    print(\"Accuracy:\", metrics.accuracy_score(y, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[39m=\u001b[39m XGBClassifier(n_estimators\u001b[39m=\u001b[39m\u001b[39m110\u001b[39m, nthread\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, seed\u001b[39m=\u001b[39m\u001b[39m1729\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m model\u001b[39m.\u001b[39mfit(X_train, y_train_buckets, eval_metric\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mauc\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/NLP/lib/python3.11/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/NLP/lib/python3.11/site-packages/xgboost/sklearn.py:1433\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1431\u001b[0m     expected_classes \u001b[39m=\u001b[39m cp\u001b[39m.\u001b[39marange(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_)\n\u001b[1;32m   1432\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1433\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(np\u001b[39m.\u001b[39masarray(y))\n\u001b[1;32m   1434\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_)\n\u001b[1;32m   1435\u001b[0m     expected_classes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/NLP/lib/python3.11/site-packages/numpy/lib/arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    272\u001b[0m ar \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(ar)\n\u001b[1;32m    273\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     ret \u001b[39m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[1;32m    275\u001b[0m                     equal_nan\u001b[39m=\u001b[39mequal_nan)\n\u001b[1;32m    276\u001b[0m     \u001b[39mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[1;32m    278\u001b[0m \u001b[39m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/NLP/lib/python3.11/site-packages/numpy/lib/arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[1;32m    334\u001b[0m     aux \u001b[39m=\u001b[39m ar[perm]\n\u001b[1;32m    335\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 336\u001b[0m     ar\u001b[39m.\u001b[39msort()\n\u001b[1;32m    337\u001b[0m     aux \u001b[39m=\u001b[39m ar\n\u001b[1;32m    338\u001b[0m mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(aux\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mbool_)\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(n_estimators=110, nthread=-1, seed=1729)\n",
    "model.fit(X_train, y_train_buckets, eval_metric=\"auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmax of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m evaluate_and_display(model, X_test, y_test_buckets)\n",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m, in \u001b[0;36mevaluate_and_display\u001b[0;34m(model, x, y)\u001b[0m\n\u001b[1;32m      6\u001b[0m y_hat \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mif\u001b[39;00m  \u001b[39mtype\u001b[39m(XGBClassifier()) \u001b[39m==\u001b[39m \u001b[39mtype\u001b[39m(model):\n\u001b[0;32m----> 8\u001b[0m     y_hat \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(x)\u001b[39m.\u001b[39mround()\n\u001b[1;32m      9\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     10\u001b[0m     y_hat \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mtransform(x)\u001b[39m.\u001b[39mround()\n",
      "File \u001b[0;32m~/miniconda3/envs/NLP/lib/python3.11/site-packages/xgboost/sklearn.py:1539\u001b[0m, in \u001b[0;36mXGBClassifier.predict\u001b[0;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1535\u001b[0m     \u001b[39mreturn\u001b[39;00m class_probs\n\u001b[1;32m   1537\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(class_probs\u001b[39m.\u001b[39mshape) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m   1538\u001b[0m     \u001b[39m# multi-class, turns softprob into softmax\u001b[39;00m\n\u001b[0;32m-> 1539\u001b[0m     column_indexes: np\u001b[39m.\u001b[39mndarray \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(class_probs, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m   1540\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(class_probs\u001b[39m.\u001b[39mshape) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m class_probs\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1541\u001b[0m     \u001b[39m# multi-label\u001b[39;00m\n\u001b[1;32m   1542\u001b[0m     column_indexes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(class_probs\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36margmax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/NLP/lib/python3.11/site-packages/numpy/core/fromnumeric.py:1242\u001b[0m, in \u001b[0;36margmax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m \u001b[39mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1239\u001b[0m \u001b[39m(2, 1, 4)\u001b[39;00m\n\u001b[1;32m   1240\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1241\u001b[0m kwds \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mkeepdims\u001b[39m\u001b[39m'\u001b[39m: keepdims} \u001b[39mif\u001b[39;00m keepdims \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39m_NoValue \u001b[39melse\u001b[39;00m {}\n\u001b[0;32m-> 1242\u001b[0m \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39m\u001b[39margmax\u001b[39m\u001b[39m'\u001b[39m, axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/miniconda3/envs/NLP/lib/python3.11/site-packages/numpy/core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "\u001b[0;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
     ]
    }
   ],
   "source": [
    "evaluate_and_display(model, X_test, y_test_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
