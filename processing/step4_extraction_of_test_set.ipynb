{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKIJue8ZwhuK",
        "outputId": "8bb6fc4b-373e-4d6e-f638-6143c8ba3a5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/UCY/NLP/AirBnB_project\n"
          ]
        }
      ],
      "source": [
        "# This mounts your Google Drive to the Colab VM.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# TODO: Enter the foldername in your Drive where you have saved the unzipped\n",
        "FOLDERNAME = 'UCY/NLP/AirBnB_project'\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "# Now that we've mounted your Drive, this ensures that\n",
        "# the Python interpreter of the Colab VM can load\n",
        "# python files from within it.\n",
        "import sys\n",
        "ROOT_PATH = '/content/drive/My Drive/{}'.format(FOLDERNAME)\n",
        "sys.path.append(ROOT_PATH)\n",
        "%cd /content/drive/My\\ Drive/$FOLDERNAME/\n",
        "\n",
        "SUBMODULES = ['processing', 'utils', 'Dataset']\n",
        "\n",
        "import sys\n",
        "for module in SUBMODULES:\n",
        "  sys.path.append('/content/drive/My Drive/{}/{}'.format(FOLDERNAME, module))\n",
        "\n",
        "EMBEDDINGS_PATH = f'{ROOT_PATH}/embeddings'\n",
        "DATASET_PATH = f'{ROOT_PATH}/Dataset'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VT7_yV43whuZ"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from dataloader import Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "cmS_rdtkwhuc"
      },
      "outputs": [],
      "source": [
        "data = Dataloader(\n",
        "    listing_path = f'{DATASET_PATH}/listings',\n",
        "    comments_path = f'{DATASET_PATH}/comments',\n",
        ")\n",
        "df = data.getListings()\n",
        "\n",
        "scores_conlumns = [ col for col in df.columns if \"score\" in col ]\n",
        "scores = df[scores_conlumns]\n",
        "\n",
        "# loads pre_processed data\n",
        "with open(f'{EMBEDDINGS_PATH}/listing_name_embeddings.pkl', 'rb') as f:\n",
        "    listing_name = pickle.load(f)\n",
        "    \n",
        "with open(f'{EMBEDDINGS_PATH}/listing_description_embeddings.pkl', 'rb') as f:\n",
        "    listing_description = pickle.load(f)\n",
        "\n",
        "with open(f'{EMBEDDINGS_PATH}/listing_neighborhood_overview_embeddings.pkl', 'rb') as f:\n",
        "    listing_neighborhood = pickle.load(f)\n",
        "\n",
        "with open(f'{EMBEDDINGS_PATH}/listing_host_about_embeddings.pkl', 'rb') as f:\n",
        "    listing_host_about = pickle.load(f)\n",
        "\n",
        "with open(f'{EMBEDDINGS_PATH}/listing_processed_data.pkl', 'rb') as f:\n",
        "    listings_numeric = pickle.load(f)\n",
        "\n",
        "with open(f'{EMBEDDINGS_PATH}/comments_embeddings.pkl', 'rb') as f:\n",
        "    comments = pickle.load(f)\n",
        "\n",
        "with open(f'{EMBEDDINGS_PATH}/comments_mean_emb.pkl', 'rb') as f:\n",
        "    comments_mean = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"listing_name:\", listing_name.shape)\n",
        "print(\"listing_description:\", listing_description.shape)\n",
        "print(\"listing_neighborhood:\", listing_neighborhood.shape)\n",
        "print(\"listing_host_about:\", listing_host_about.shape)\n",
        "print(\"listings_numeric:\", listings_numeric.shape)\n",
        "print(\"comments:\", comments.shape)\n",
        "print(\"comments_mean:\", comments_mean.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9t3KiFGF0MmR",
        "outputId": "63e09b2f-4364-47ef-e1ae-5b801ea76e0c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "listing_name: (6998, 384)\n",
            "listing_description: (6998, 384)\n",
            "listing_neighborhood: (6998, 384)\n",
            "listing_host_about: (6998, 384)\n",
            "listings_numeric: (6998, 34)\n",
            "comments: (6998, 384)\n",
            "comments_mean: (384,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A dataset class that can be used to access to the dataset while granting some extra functions\n",
        "class Dataset():\n",
        "  def __init__(self, x: pd.DataFrame, y: pd.DataFrame) -> None:\n",
        "      self.x=x\n",
        "      self.y=y\n",
        "\n",
        "  def get(self):\n",
        "    return self.x, self.y.review_scores_rating\n",
        "\n",
        "  def getEmbeddings(self):\n",
        "    embeddings_conlumns = [ col for col in df.columns if \"embedding\" in col ]\n",
        "    return self.x[embeddings_conlumns]\n",
        "\n",
        "  def getNotEmbeddings(self):\n",
        "    not_embeddings_conlumns = [ col for col in df.columns if \"embedding\" not in col ]\n",
        "    return self.x[not_embeddings_conlumns]\n",
        "\n",
        "  def getAllScores(self):\n",
        "    return self.y\n",
        "\n"
      ],
      "metadata": {
        "id": "lUjS2XNhxAoN"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate train - Test Split this is done Once to be able to compare results\n",
        "comments_pd = pd.DataFrame(comments, columns= [ f'comments_average_embeddings_{i}' for i in range(comments.shape[1])])\n",
        "dataset_pd = pd.concat([listings_numeric, listing_name, listing_description, listing_neighborhood, listing_host_about, comments_pd], axis=1)\n",
        "dataset_pd.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RiJACopyOtp",
        "outputId": "dcf35c09-b79d-425a-c4a9-aa2e604ec434"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6998, 1954)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using the score as a referenc to understand which rows to drop, if no score is aviable \n",
        "dataset_with_no_null_scores_x = dataset_pd[df['review_scores_rating'].notna()]\n",
        "dataset_with_no_null_scores_y = scores[df['review_scores_rating'].notna()]"
      ],
      "metadata": {
        "id": "joqUEcms6gf0"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(dataset_with_no_null_scores_x, dataset_with_no_null_scores_y, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "Le9M87ax3-Zh"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = Dataset(x_train, y_train)\n",
        "dataset_test = Dataset(x_test, y_test)"
      ],
      "metadata": {
        "id": "AqwE4-CF4rsG"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f'{ROOT_PATH}/train_dataset.pkl', 'wb') as f:\n",
        "    pickle.dump(dataset_train, f)\n",
        "\n",
        "with open(f'{ROOT_PATH}/test_dataset.pkl', 'wb') as f:\n",
        "    pickle.dump(dataset_test, f)"
      ],
      "metadata": {
        "id": "R8ulrgPg8LX8"
      },
      "execution_count": 42,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}